{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Digit Recognition via Machine Learning \n",
    "\n",
    "Machine learning algorithms are one of the ways with which we create Artificial Intelligence. The distinguishing feature of machine learning compared to usual programming is training. Instead of programming the steps to get to the solution to a problem we program a machine learning algorithm to be trained to learn the steps towards the desired solution. \n",
    "\n",
    "In this notebook, you shall explore how to create a simple neural network using the tensorflow and keras libraries. The model shall aim to correctly tag hand written digits between 0 and 9, taken from the MNIST digit dataset.\n",
    "\n",
    "\n",
    "## 1.1 The MNIST Dataset\n",
    "The MNIST dataset is a large dataset consisting of 70,000 digits, split into 60,000 used for training, and 10,000 used for testing. It is made up of handwritten digits, from a mix of digits from employees of the American Census Bureau, and American high school students. Each digit has an associated label, which defines the intended value of each digit. It has become a well established dataset within the machine learning community, and is often recommended as the first task those new to machine learning should attempt. \n",
    "\n",
    "## 1.2 What is a Neural Network?\n",
    "\n",
    "The neural network model is loosely based on the human brain. A Neuron receives a number of input signals, these signals are then processed at the neuron which passes on a new signal (fires) to the next neuron only if a certain condition is met. \n",
    "\n",
    "A neural network is a collection of artificial neurons organised in layers (as shown in the image below) that connect together allowing the neural network to learn complexities and make sophisticated decisions. The artificial neurons work by simple multiplication between the input signals (variables) coming into the node and a set of weights. If the produce of this multiplication is above a certain threshold, the neuron fires! \n",
    "\n",
    "\n",
    "![Neural Network](https://i.stack.imgur.com/OH3gI.png)\n",
    "\n",
    "The neurons must be trained to process the signal appropriately so as to maximise the accuracy in decision making. To understand this, let's go back to the human brain analogy. Say you were teaching your younger sibling how to recognise numbers. You would repeatedly show them pictures of numbers and tell them which one is which. You might test their knowledge by giving them a new image and then seeing whether they recognised what digit it was. You might then praise them for getting it right and correct them if they got it wrong. \n",
    "\n",
    "\n",
    "Neurons are trained in a similar way. To train a neural network to learn how to recognise handwritten digits we would give it thousands of images of labelled handwritten digits. It will pass these images through the network in the form of numbers between 0 and 1, compute the product between these inputs (the image in the form of numbers) and the weights at all neurons. The final product at the end of the  neural network will be used to reach a decision. The training process updates the weights such that the accuracy is maximised. \n",
    "\n",
    "This process is similar to maximisation (or minimisation) problems you may have done in A-Level Maths using differentiation to find the minimum/maximum value of function. \n",
    "\n",
    "All this might sound a bit confusing! Don’t worry it is a lot to take in within a short space of time. Ask your mentors about anything you’re unsure about. \n",
    "\n",
    "We're now going to learn how to build and apply a neural network in Python using the Keras library. \n",
    "\n",
    "\n",
    "## 1.3 Neural Networks in Keras\n",
    "\n",
    "The algorithm for predicting digits can be summarised with the following steps:\n",
    "\n",
    "* Import libraries and load data.\n",
    "* Build neural network. \n",
    "* Training Neural Network. \n",
    "* Make predictions about digits using the Neural Network. \n",
    "\n",
    "\n",
    "## 1.4 Importing libraries and loading \n",
    "\n",
    "The Keras library is a free open-source tool to quickly and easily develop with neural networks. It does a lot of the heavy lifting for us making it an ideal tool for prototyping. Just like any popular Python library, it is well documented with guides explaining how to use it. These are available here: https://keras.io/\n",
    "\n",
    "In this exercise, your mentors will guide you through a lot of the code that has already been written for you so that you can focus specifically on building the neural network. It is still valuable to understand what is going on so make sure you ask questions! \n",
    "\n",
    "In the code cell below, we import the required libraries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use tensorflow, and import the mnist dataset\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "# matplotlib is a popular library for making high quality plots\n",
    "import matplotlib.pyplot as plt\n",
    "# Numpy is a popular library for fast manipulation of numbers and arrays\n",
    "import numpy as np\n",
    "from time import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Data preparation\n",
    "We can easily load our data using built in functions, as shown in the cell below. \n",
    "### Task 1 - Look through the digits\n",
    "Try changing the 'index' variable to a different number, to see examples of other digits in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "X_val, Y_val = X_train[:5000], Y_train[:5000]\n",
    "X_train, Y_train = X_train[5000:], Y_train[5000:]\n",
    "index = 28\n",
    "\n",
    "plt.imshow(X_train[index]) # Show a single image\n",
    "plt.colorbar() # Show range of values for each pixel in image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The colourbar on the right hand side of the plot indicates the value of each pixel in the image. We see that the values range from 0, to 255. While we could attempt to feed these images into a model directly, research has shown that models will train faster if all input values are within a smaller range, such as between 0 and 1. We can achieve this range by scaling the value of each pixel in each image down. This is implemented in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the images to have values between 0 and 1\n",
    "X_train = X_train/255.0\n",
    "X_val = X_val/255.0\n",
    "X_test = X_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 28\n",
    "plt.imshow(X_train[index])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our image pixels all have a value between 0 and 1 as desired. As a final step, we shall print the shape of each dataset. This is important as we shall need to ensure our model can take the required input size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the shape of the images and their associated labels\n",
    "print('Shape X_train: ' + str(X_train.shape))\n",
    "print('Shape Y_train: ' + str(Y_train.shape))\n",
    "print('Shape X_val:   ' + str(X_val.shape))\n",
    "print('Shape Y_val:   ' + str(Y_val.shape))\n",
    "print('Shape X_test:  '  + str(X_test.shape))\n",
    "print('Shape Y_test:  '  + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that we have 60000 images in out training dataset, and 10000 in our test dataset. All images are the same size, 28x28 pixels. \n",
    "\n",
    "## 1.6 Creating a Model\n",
    "\n",
    "With everything we have now, we can attempt to create our first model. A model consists of several main components\n",
    "* An input layer\n",
    "* One or more hidden layers\n",
    "* An output layer\n",
    "\n",
    "The size of the input layer depends on the size of the image we want to give the model (28x28). The size of the output layer depends on the number of classes the model must predict. In this case, we want to predict the 10 digits (0-9), and so our output layer must have a size of 10.\n",
    "\n",
    "Each layer also has an _activation function_. This is a function which is applied to the output of a given layer, before those values are passed to the next layer. An activation function allows a model to output a wider range of values, and so can help it get more accurate results.\n",
    "In the final layer, we use the 'softmax' activation function. This function takes all the output values, and scales them so their total is 1. This means we can interpret the outputs as the probability the model thinks a given image is a given digit.\n",
    "\n",
    "Before we can train the model, we must _compile_ it. This sets things such as the loss function (this measures how accurately our model is predicting digits, the lower the loss function the better!), and the optimizer, which aims to increase training speed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)), # An input layer that takes the 28x28 image, and flattens into a 1x784 array\n",
    "  tf.keras.layers.Dense(16, activation='sigmoid'), # A single hidden layer with 16 neurons\n",
    "  tf.keras.layers.Dense(10, activation='softmax') # An output layer of size 10, for the 10 possible digits\n",
    "])\n",
    "model.compile(optimizer='adam',\n",
    "             loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7 Training the Model\n",
    "\n",
    "Our model is now built and compiled, and so we can now train it using _model.fit_. We must provide the data we wish to train on, as well as the number of epochs. A single epoch means we train the model on each image once. Multiple epochs means we train on each image multiple times, updating our model continuously. We can also provide the _batch size_. The batch size is how many images are passed through the model before the weight update, the learning process, is applied. In tensorflow, if no batch size is provided, a default size of 32 is used. In general, a larger batch size will result in a faster training time per epoch, but may also result in your model requiring more models to train.\n",
    "\n",
    "Note, we also use 'validation_data' when we train this model. This is data that is not used for training, and so is data the model does not see. It is best practise to use a seperate dataset for training, validation, and testing. We did this earlier when we loaded in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit(X_train, # The input data\n",
    "                 Y_train, # The labels\n",
    "                 epochs=5, # Number of times to train on full dataset\n",
    "                 batch_size=32, # How many images before we update neuron values\n",
    "                 shuffle=True, # Shuffling helps with model training\n",
    "                 validation_data=(X_val, Y_val)) # Define validation data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.8 Evaluate the Model\n",
    "To evaluate our model, we pass the testing dataset through it using _model.evaluate_. We can also look at the training/testing accuracy at each epoch end, by accessing the model training history. This lets use see things such as the training and validation loss at each epoch, as well as the training/validation accuracy at each epoch. The accuracy, a value between 0 and 1, can be thought of as how often the model correctly tags an image. I.e. a test accuracy of 95% means that if the model is given 100 images, we expect it will correcly tag 95 of them, and incorrectly tag 5.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8)) # Define the size of the plot\n",
    "# Plot the training accuracy, and validation accuracy\n",
    "plt.plot(hist.history['accuracy'], label=\"Train accuracy\")\n",
    "\n",
    "plt.legend() # Add a legend\n",
    "\n",
    "# Add a title and exist labels\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Plot of model accuracy per epoch\")\n",
    "\n",
    "# Print the final test accuracy\n",
    "(loss, acc) = model.evaluate(X_test, Y_test, verbose=2)\n",
    "print(f\"The final model loss was {round(loss, 3)}\")\n",
    "print(f\"The final model accuracy was {round(acc, 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2 - Loss per epoch plot\n",
    "Above, we made a plot showing the training accuracy and validation accuracy per epoch. Can you instead make a similar plot that shows the training and validation loss at each epoch? They can be accessed in the model training history in a similar way to the above cell, using the keys _'loss'_ and _'val_loss'_. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make your plot here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To give a more concrete view of how the model works, the two functions below are provided. The first will plot an individual image, as well as the models outputs for the image. The second function finds images which the model incorrectly tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PlotModelOutput(model, x, y, index=0):\n",
    "    '''\n",
    "    Produces a plot in MatPlotLib showing the image at the provided\n",
    "    index within the 'x' array, as well as the models output for this\n",
    "    image.\n",
    "    \n",
    "    Parameters:\n",
    "        model - The trained tensorflow model\n",
    "        x - an array containing all images\n",
    "        y - an array containing labels for all images\n",
    "        index - the index within the 'x' array that we wish to plot/\n",
    "                show model output for\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # Setup 2 plots next to each other\n",
    "    fig, (ax1, ax2) = plt.subplots(1,2, figsize=(12,8))\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Get the image we wish to show, and the models predictions\n",
    "    image = x[index]\n",
    "    prediction = model.predict(np.expand_dims(image, axis=0))[0]\n",
    "    \n",
    "    # Plot the image, and model output\n",
    "    ax1.imshow(image.reshape(28,28))\n",
    "    ax2.bar(np.linspace(0,9, 10), prediction)\n",
    "    ax2.set_xticks(np.linspace(0,9,10))\n",
    "    \n",
    "    # Define thetitles and axis labels for the plots\n",
    "    ax1.set_title(\"Image\")\n",
    "    ax2.set_title(\"Model digit predictions\")\n",
    "    ax2.set_xlabel(\"Digit\")\n",
    "    ax2.set_ylabel(\"Model output\")\n",
    "    fig.suptitle(f\"Image tag: {y[index]}, Model output: {np.argmax(prediction)}\")\n",
    "    \n",
    "    \n",
    "def FindNextWrongPrediction(model, x, y, index=0):\n",
    "    '''\n",
    "    Finds the next image index that the model incorrectly predicts\n",
    "    \n",
    "    Parameters:\n",
    "        model - the trained tensorflow model\n",
    "        x - the images to test\n",
    "        y - the correct labels for each image\n",
    "        index - the start index to search from (default is 0)\n",
    "        \n",
    "    Returns:\n",
    "        i - the next image index that the model predicts incorrecly. Returns -1 \n",
    "            if no incorrect prediction is found.\n",
    "    '''\n",
    "    # Get all model predictions\n",
    "    predictions = model.predict(x)\n",
    "    \n",
    "    # Iterate from 'index' until all images searched\n",
    "    for i in range(index, len(predictions)):\n",
    "        \n",
    "        # If the current image prediction does not match the label,\n",
    "        # we return the index\n",
    "        if(np.argmax(predictions[i]) != y[i]):\n",
    "            return i\n",
    "        \n",
    "    # Should only happen if no incorrect digit is found\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a digit, as well as the models output\n",
    "PlotModelOutput(model, X_test, Y_test, 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that this digit was easy to tag. The model predicted with near 100% certainty that this digit was a '1'.\n",
    "Let us now search for an incorrectly tagged image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get an index that is incorrectly tagged\n",
    "index_inc = FindNextWrongPrediction(model, X_test, Y_test, index=0)\n",
    "print(f\"Next incorrect index was {index_inc}\")\n",
    "# Plot the image and the model output for incorrectly tagged image.\n",
    "PlotModelOutput(model, X_test, Y_test, index_inc)\n",
    "\n",
    "# Get the NEXT incorrect image by searching from index_inc + 1\n",
    "index_inc = FindNextWrongPrediction(model, X_test, Y_test, index=index_inc + 1)\n",
    "print(f\"Next incorrect index was {index_inc}\")\n",
    "# Plot the image and the model output for incorrectly tagged image.\n",
    "PlotModelOutput(model, X_test, Y_test, index_inc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3 - Look at other incorrect model outputs\n",
    "The above code searches for the next incorrectly tagged image from the 'index' value. Look at the next few incorrectly tagged images. Are the images hard to discern even for a human? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4 - Improving the Model\n",
    "So far, we have made a simple model using only 2 hidden layers, both using the sigmoid activation function.\n",
    "Now its your turn, try and add or remove layers, changing the number of neurons in a layer, or changing the activation function. An overview of popular activation functions is provided [here](https://towardsdatascience.com/7-popular-activation-functions-you-should-know-in-deep-learning-and-how-to-use-them-with-keras-and-27b4d838dfe6).\n",
    "\n",
    "Try and get the highest accuracy for the test dataset via _model.evaluate_. For whatever you change, add it to the 'changed variable' list in the code cell below, and add the accuracy to the 'results' list, then you can easily plot your results.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(16, activation='sigmoid'), # Add layers, change neuron count, etc\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adam',\n",
    "             loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "             metrics=['accuracy'])\n",
    "print(\"Start model training\\n\")\n",
    "model.fit(X_train, Y_train, epochs=10, batch_size=32)\n",
    "print(\"Model training complete\\n\")\n",
    "model.evaluate(X_test, Y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your results!\n",
    "changed_variable = []\n",
    "results = []\n",
    "\n",
    "plt.plot(changed_variable, results)\n",
    "# Add a title, and axis label!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Introducing a Convolutional Neural Network\n",
    "\n",
    "So far, we have looked only at the most basic form of a deep neural network, where we take our image and transform it into a 1 dimensional list of numbers. The problem with this approach, is that an image that is flipped, or translated, or rotated, will register as a different image to the neural network. For image recognition tasks this is a problem. To improve, we can utilise what is known as a convolutional neural network (CNN).\n",
    "\n",
    "## 2.1 How a CNN works\n",
    "A CNN utilises a 'filter'. This filter is applied to our image, to create a new _filtered_ image. This filter works on the 2D image, rather than a 1D representation, and as a result is better able to find relationships in groups of pixels. Due to this, they are popular in image recognition tasks such as this, or any task where there is a distinct spatial relationship between data points.\n",
    "\n",
    "## 2.2 Data preparation\n",
    "In a CNN, we let the model learn the optimal kernal. By doing so, we allow for our model to better identify our digits.\n",
    "First, we need to slightly change the shape of our datasets so they can be easily passed to the CNN layer, we do this in the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cnn = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "X_test_cnn = X_test.reshape(X_test.shape[0], 28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 2.3 First CNN\n",
    "\n",
    "To make a CNN, we simply add a Conv2D layer at the start of our model. We must also add a 'Flatten' layer after the Conv2D layer, so that the remaining dense layers can function.\n",
    "The Conv2D layers has 2 main different parameters compared to the dense layers. The first parameter is the number of individual kernels to produce. For example, if we choose 8, a total of 8 kernals shall be produced, resulting in 8 seperate images. The second parameter defines the size of each kernel. For example, (3, 3) will use kernels that are 3x3.\n",
    "A basic CNN is implemented below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv2D(4, (3,3), activation='relu', input_shape=(28,28,1)),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(16,activation='sigmoid'),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn.compile(optimizer='adam',\n",
    "             loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "             metrics=['accuracy'])\n",
    "print(\"Start model training\\n\")\n",
    "model_cnn.fit(X_train_cnn, Y_train, epochs=5, batch_size=32)\n",
    "print(\"Model training complete\\n\")\n",
    "(loss, acc) = model_cnn.evaluate(X_test_cnn, Y_test, verbose=2)\n",
    "print(\"The final CNN accuracy was \" + str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Start searching from the first image\n",
    "index_inc = 0\n",
    "for i in range(5):\n",
    "    # Get an index that is incorrectly tagged\n",
    "    index_inc = FindNextWrongPrediction(model_cnn, X_test_cnn, Y_test, index_inc)\n",
    "    # Plot the image and the model output for incorrectly tagged image.\n",
    "    PlotModelOutput(model_cnn, X_test_cnn, Y_test, index_inc)\n",
    "    # Add 1 to this number so we search for the next incorrect index\n",
    "    index_inc+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5 -  Improving the CNN\n",
    "\n",
    "Now that we've got a simple CNN working, its your turn to play around and see if you can improve the final accuracy! Once again, write your results in the lists a couple code cells below, so you can make some plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change some stuff to try and improve the accuracy!\n",
    "model_cnn = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv2D(4, (3,3), activation='relu', input_shape=(28,28,1)),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(16, activation='sigmoid'),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn.compile(optimizer='adam',\n",
    "             loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "             metrics=['accuracy'])\n",
    "print(\"Start model training\\n\")\n",
    "model_cnn.fit(X_train_cnn, Y_train, epochs=5)\n",
    "print(\"Model training complete\\n\")\n",
    "model_cnn.evaluate(X_test_cnn, Y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your results!\n",
    "changed_variable = []\n",
    "results = []\n",
    "\n",
    "plt.plot(changed_variable, results)\n",
    "# Add a title, and axis label!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Model performance on noisy dataset\n",
    "We have shown that even simple models can achieve a high accuracy on our testing dataset. However, while the model performance is impressive, it is important to highlight that it isn't perfect. The model will struggle a lot if we change our testing dataset even slightly. We show this below, by adding noise to our testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AddNoise(images, f):\n",
    "    '''\n",
    "    Adds noise to the images provided.\n",
    "    Parameters:\n",
    "        images - array holding all images\n",
    "        f - the maximum noise to add to each pixel\n",
    "    '''\n",
    "    if(len(images.shape) == 3):\n",
    "        images = images + f * np.random.rand(images.shape[0], images.shape[1], images.shape[2])\n",
    "    elif(len(images.shape) == 4):\n",
    "        images = images + f * np.random.rand(images.shape[0], images.shape[1], images.shape[2], images.shape[3])\n",
    "\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_cnn_noise = AddNoise(X_test_cnn, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we show a single noise image. Try and change the index to see what the other images look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 7\n",
    "\n",
    "plt.imshow(X_test_cnn_noise[index].reshape(28,28))\n",
    "plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6 - Model accuracy for different test noise\n",
    "Try changing the noise amount in the cell below. Make a note of the chosen noise, and the model accuracy, in the list in the next code cell. What happens as you increase the noise? How well can you distingush noisy images, compared to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_amount = 0.5\n",
    "X_test_cnn_noise = AddNoise(X_test_cnn, noise_amount)\n",
    "(loss, acc) = model_cnn.evaluate(X_test_cnn_noise, Y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your results!\n",
    "noise = []\n",
    "results = []\n",
    "\n",
    "plt.plot(changed_variable, results)\n",
    "# Add a title, and axis label!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, we look at the model outputs for the noisy dataset. Notice how images which we as humans can easily recognise, are very difficult for the model to deal with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Start searching from the first image\n",
    "index_inc = 0\n",
    "for i in range(5):\n",
    "    # Get an index that is incorrectly tagged\n",
    "    index_inc = FindNextWrongPrediction(model_cnn, X_test_cnn_noise, Y_test, index_inc)\n",
    "    # Plot the image and the model output for incorrectly tagged image.\n",
    "    PlotModelOutput(model_cnn, X_test_cnn_noise, Y_test, index_inc)\n",
    "    # Add 1 to this number so we search for the next incorrect index\n",
    "    index_inc+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Advanced - Making it Scientific\n",
    "So far, we have asked you to change things bit by bit and write the results yourself. Instead, we can automate this task using a for loop. \n",
    "\n",
    "It was mentioned earlier that increasing batch size can decrease training time per epoch, but may need more epochs to achieve the same accuracy. We shall now test this claim below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_to_test = [8, 16, 32, 64, 128] # I choose powers of 2 because they look nice\n",
    "# Create empty lists to store the training times and accuracy\n",
    "training_times = []\n",
    "training_acc = []\n",
    "\n",
    "\n",
    "for batch_size in batch_size_to_test:\n",
    "    # Create a new model for each test\n",
    "    model = tf.keras.models.Sequential([\n",
    "      tf.keras.layers.Flatten(input_shape=(28, 28)), \n",
    "      tf.keras.layers.Dense(16, activation='sigmoid'), \n",
    "      tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer='adam',\n",
    "             loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "             metrics=['accuracy'])\n",
    "    # Get the current time before we train the model\n",
    "    start = time()\n",
    "    print(\"Training model with batch size \" + str(batch_size))\n",
    "    # Train the model with constant number of epochs, but \n",
    "    # with different batch sizes\n",
    "    model.fit(X_train, Y_train, epochs=10, batch_size=batch_size, verbose=0)\n",
    "    \n",
    "    # Calculate time taken, and model accuracy\n",
    "    time_taken = time() - start\n",
    "    (loss, acc) = model.evaluate(X_test, Y_test, verbose=0)\n",
    "    \n",
    "    # Append these values to our results list\n",
    "    training_times.append(time_taken)\n",
    "    training_acc.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(batch_size_to_test, training_times)\n",
    "plt.xlabel(\"Batch Size\")\n",
    "plt.ylabel(\"Training Time (s)\")\n",
    "plt.title(\"Plot comparing model batch size to model training time.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(batch_size_to_test, training_acc)\n",
    "plt.xlabel(\"Batch Size\")\n",
    "plt.ylabel(\"Model Accuracy\")\n",
    "plt.title(\"Plot comparing model batch size to model accuracy.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As was originially suggested, increasing the batch size resulted in a drastic decrease in training time, at the cost of a lower final accuracy for the model. We often see such trade offs in machine learning, where a process which decreases training time may slightly reduce accuracy. Its up to the scientist to decide if a trade off is worth it!\n",
    "\n",
    "In this case, we see that the final accuracy decreases slightly, while the training time decreases by a factor of 10. This decrease in training time could mean we could train for more epochs, or use a more complex model architecture (more layers, more neurons per layer).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 7 - Your turn!\n",
    "\n",
    "Now that we've shown how you can easily test a range of values for a model, its your turn to see what trends you can find. Try changing some other aspect of the model, and see how this effects the training time and model accuracy. Good luck!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
