{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 Searching for $H\\rightarrow b\\bar{b}$\n",
    "\n",
    "One of the primary physics objectives of the Large Hadron Collider is to study the Higgs Boson and understand the process with which particles acquire mass. The Higgs Boson's decays channels along with the respective branching ratios are shown in the figure below. \n",
    "\n",
    "<img src=\"https://physicsforme.files.wordpress.com/2012/07/higgs_decay.jpg\" width=\"400\" />\n",
    "\n",
    "\n",
    "\n",
    "In 2012 the Higgs Boson was discovered in the $H\\rightarrow\\gamma\\gamma$ and $H\\rightarrow ZZ \\rightarrow 4l$. The plot below shows a clear excess of signal events over background around 125 GeV in the $H\\rightarrow ZZ \\rightarrow 4l$ 'golden channel'. \n",
    "\n",
    "<img src=\"https://3c1703fe8d.site.internapcdn.net/newman/gfx/news/hires/2017/newatlasprec.png\" width=\"400\" />\n",
    "\n",
    "\n",
    "But if the Higgs Boson predominantly decays to a pair of $b$-quarks, why wasn't it discovered in the $H\\rightarrow b\\bar{b}$ channel? \n",
    "\n",
    "The discovery channels leave a clean signature in the detector that is easy to isolate making searches in the $H\\rightarrow\\gamma\\gamma$ or $H\\rightarrow ZZ \\rightarrow 4l$ favourable. However, $H\\rightarrow b\\bar{b}$ searches aren't so straightforward!\n",
    "\n",
    "Here's why:\n",
    "\n",
    "## Large background \n",
    "\n",
    "Firstly, the $H\\rightarrow b\\bar{b}$ process at the LHC has enourmous amount of background with final states that are the same as the signal i.e. two $b$-quarks. The figure below shows the cross sections (likelihood) of a Higgs event and compared to a bb event at the LHC. In the LHC current operational energy, only around 1 in a trillion proton-proton collisions create a Higgs boson. \n",
    "\n",
    "\n",
    "<img src=\"../docs/images/lhc_cross_sections.png\" width=\"400\" />\n",
    "\n",
    "Hence, the signal can get drowned out in with the signal-like background. \n",
    "\n",
    "## Jet Production\n",
    "\n",
    "Secondly, precisely measuring and distinguishing $b$-quarks from say $c$-quarks is also challenging. When a pair of $b$-quarks is created in the ATLAS detector they go through a process known as hadronisation and form [jets](https://www.youtube.com/watch?v=FMH3T05G\\_to). The jets must be identified as originating from b-quarks (b-jets) by a process known as $b$-tagging. This extra level of complexity along with the large background makes searches for $H\\rightarrow b\\bar{b}$ challenging. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 One - Lepton Channel\n",
    "\n",
    "The process we will be searching for is shown in the Feynman Diagram below. A Higgs Boson is radiated off a $W^\\pm$ boson which subsequently decays to a pair of _b_-quarks. The $W^\\pm$ boson then goes on to decay into a lepton and a corresponding neutrino. \n",
    "\n",
    "<img src=\"images/one-lepton.png\" width=\"350\" />\n",
    "\n",
    "\n",
    "\n",
    "The final state products of a 1-lepton channel $H\\rightarrow b\\bar{b}$ process are:\n",
    "   * A Neutrino\n",
    "   * A charged Lepton (e u)\n",
    "   * 2 _b_-jets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Separating Signal from Background\n",
    "\n",
    "\n",
    "We separate ATLAS events using *Kinematic* (momentum, energy, mass etc) and Topological parameters (spatial separation between particles). A list of the event variables that we will be using in this exercise is shown below: \n",
    "\n",
    "\n",
    "\n",
    "| Variable        | Description           | Label  |\n",
    "| ------------- |:-------------:| -----:|\n",
    "|$\\Delta R(b_1b_2)$      | Angle between the two *b*-tagged jets | dRBB |\n",
    "| $p_T^V$      | Missing Transverse Momentum      |   pTV |\n",
    "| $m_{top}$ | Reconstructed Top Quark Mass      |    Mtop |\n",
    "| $E^{Miss}_{T}$ | Missing Transverse Energy     |    MET |\n",
    "\n",
    "\n",
    "                    Table 1: Kinematic and topological paramaeters used to identify events. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.0 Finding signal in the data\n",
    "In particle physics, we want to try and find some evidence of a signal process, such as the production of a Higgs boson, which then decays to 2 b-jets. We do this by measuring the final particles, the b-jets, and then adding up their properties to find the properties of the Higgs. By doing this, we can find properties such as the Higgs mass. In the first example below, we show an ideal case, where we have a lot of Higgs bosons produced, and no background.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "if not Path(\"VHbb_data_2jet.csv\").exists():\n",
    "    # Download dataset, and a custum library from github\n",
    "    !wget https://raw.githubusercontent.com/nikitapond/in2HEP/StudentWeek/data-v2/VHbb_data_2jet.csv\n",
    "if not Path(\"ucl_masterclass.py\").exists():\n",
    "    !wget https://raw.githubusercontent.com/nikitapond/in2HEP/StudentWeek/notebooks/ucl_masterclass.py\n",
    "# Importing required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from ucl_masterclass import *\n",
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1.1 An Ideal Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dummy_signal(n):\n",
    "    '''\n",
    "    Generates a dummy Higgs signal with a mean of 125 and a standard deviation of 1.\n",
    "    '''\n",
    "    return 125 + np.random.randn(n)*5\n",
    "\n",
    "def make_hist(data, title):\n",
    "    '''\n",
    "    Makes a histogram of the data.\n",
    "    '''\n",
    "    plt.hist(data, bins=np.linspace(50, 200, 50));\n",
    "    plt.xlabel(\"Mass [GeV]\")\n",
    "    plt.ylabel(\"Number of Events\")\n",
    "    plt.title(title)\n",
    "\n",
    "make_hist(generate_dummy_signal(20000), \"Dummy signal data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1.2 What about background\n",
    "\n",
    "In the above example, we can clearly see a peak at 125 GeV, highlighting a particle that exists with this mass. But this is an ideal case, with a lot of signal, and no background. What happens if we change these two factors?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dummy_background(n):\n",
    "\n",
    "    exp_bkg = np.random.exponential(100, n)\n",
    "    gaus_bkg_1 = np.random.randn(n)*30 + 100\n",
    "    gaus_bkg_2 = np.random.randn(n)*30 + 200\n",
    "    return np.concatenate([exp_bkg, gaus_bkg_1, gaus_bkg_2])\n",
    "\n",
    "# Generate a dummy background, caused by several other processes\n",
    "dummy_back = generate_dummy_background(20000)\n",
    "# Generate a dummy signal, caused by the Higgs boson, with high statistics\n",
    "dummy_signal = generate_dummy_signal(20000)\n",
    "# What we actually measure is all the signal and background\n",
    "dummy_measured = np.concatenate([dummy_back, dummy_signal])\n",
    "make_hist(dummy_measured, \"Dummy measured data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1.3 Lowering the signal\n",
    "The actual rate at which Higgs bosons is produced is signficantly smaller than the background. Lets see how that effects these plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a dummy background, caused by several other processes\n",
    "dummy_back = generate_dummy_background(10000)\n",
    "# Generate a dummy signal, caused by the Higgs boson, with low statistics\n",
    "dummy_signal = generate_dummy_signal(250)\n",
    "# What we actually measure is all the signal and background\n",
    "dummy_measured = np.concatenate([dummy_back, dummy_signal])\n",
    "\n",
    "make_hist(dummy_measured, \"Dummy measured data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above plot will look different each time you run it, due to the random numbers utilised. This is very similar to what actually happens in the ATLAS detector, with random fluctations in data occuring. Sometimes, you might get lucky and see a clear peak around 125 GeV, but a lot of the time you wont. Even worse, you might see random peaks elsewhere! So, how can we find our Higgs boson when there's so much other stuff going on? We can apply cuts!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1.4 Ideal cuts\n",
    "In this ideal example, we shall apply 'cuts' which just reduce the amount of background and signal we have, but at ideal rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bgk_factor = 0.5\n",
    "signal_factor = 0.9\n",
    "num_cuts = 4\n",
    "bkg_reduced = 1.0\n",
    "sig_reduced = 1.0\n",
    "\n",
    "dummy_back = generate_dummy_background(10000)\n",
    "dummy_signal = generate_dummy_signal(250)\n",
    "\n",
    "plt.title(\"Measured data after cuts\")\n",
    "plt.xlabel(\"Mass [GeV]\")\n",
    "plt.ylabel(\"Number of Events\")\n",
    "plt.hist(np.concatenate([dummy_back, dummy_signal]), bins=np.linspace(50, 200, 50), label=\"No cuts\");\n",
    "for i in range(num_cuts):\n",
    "    bkg_reduced *= bgk_factor\n",
    "    sig_reduced *= signal_factor\n",
    "    dummy_measured = np.concatenate([dummy_back[:int(len(dummy_back)*bkg_reduced)], dummy_signal[:int(len(dummy_signal)*sig_reduced)]])\n",
    "    plt.hist(dummy_measured, bins=np.linspace(50, 200, 50), label=f\"Cut {i+1}\");\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this final plot, we can see that after applying a series of cuts to our signal and background, we eventually start to see our peak more and more clearly. Once we can see a peak clearly above the background noise, we can use it to declare that we've found a Higgs.\n",
    "\n",
    "When it actually comes to declaring we've discovered a particle, we need to ensure that the peak we see is larger than the random noise fluctuations we see in the background. If we don't do this check, and say every peak we see is a new particle, we'd be discovering new particles every week! We aim to find a peak which is statistically significant compared to the background, this means we calculate the probability that a peak is down to random noise. To discover a particle, we require the probability of the peak being caused by random noise to be approximatly 1 in a billion!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 A more realistic example\n",
    "In the above code, we generated some dummy data, with a clear peak from the Higgs boson decay, and a few different possible background processes. When applying cuts, we just imaged we were able to apply a cut that reduced the background by 50%, while only reducing the signal by 10%. We also only generated a single variable, the sum of the mass of the two b-jets. In real data, each point represents an event in the ATLAS detector. But how do we know if the cuts we're applying are working? The way we do this is to instead work with simulations, and compare these to what we see in the data. These are called Monte-Carlo (MC) simulations, as they involve random numbers, as they simulate quantum processes which have an intrinstic random nature. When we generate MC, we know what processes we have generated, and so we can plot all the different background and signal events with different colours, to make it clear what each processes is contributing. Below, lets look at the distributions for some of our variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data into a pandas data frame\n",
    "df = pd.read_csv('VHbb_data_2jet.csv')\n",
    "df_original = deepcopy(df)\n",
    "\n",
    "# The plot_variable takes two arguments. First is the data frame used to plot the distributions and\n",
    "# second is the variable in question.\n",
    "plot_variable(df,'mBB') # Draw the mBB distribution\n",
    "plot_variable(df,'pTB1') # Draw the pTB1 distribution\n",
    "plot_variable(df,'Mtop') # Draw the pTV distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 What is Sensitivity?\n",
    "Sensitivity is the quantative measure of how much our peak sticks up above the background. It has a fancy calculation that we don't need to get into, but the rough idea is this:\n",
    "\n",
    "- Take our histogram of signal and background\n",
    "- For each bin, calculate a per bin sensitivity. The per bin sensitivity increases when we have more signal in that bin.\n",
    "- Add up the per-bin sensitivity\n",
    "\n",
    "In the below cell, we calculate the sensitivity on the variable, this is the mass we get by adding the two b-jets, which for signal represents the mass of the Higgs boson.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code below plots the mBB distribution before any selection is applied\n",
    "plot_variable(df_original,'mBB')\n",
    "# Calculate and output the sensitivity based up the original mBB distribution prior to any selection\n",
    "# The sensitivity is calculated using the profile likelihood ratio test and Asimov approach\n",
    "print(\"Sensitivity achieved before cuts \",sensitivity_cut_based(df_original))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 $H\\rightarrow b\\bar{b}$ via Sequential Cuts\n",
    "\n",
    "In this section we are going to be applying a set of selection cuts on the kinematic and topological paramaters to select signal events and reject background events. We will be applying cuts on all variables other than $m_{bb}$ and see what effect the cut has on the $m_{bb}$ distribution histogram. \n",
    "\n",
    "The $m_{bb}$ is the reconstructed mass of the two jets, if we assume both to be caused by $b$ quarks. For signal events, we expect this value to be very close to the Higgs mass of 125 GeV. We show this variable plot below\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data is loaded into a pandas data frame\n",
    "df = pd.read_csv('VHbb_data_2jet.csv')\n",
    "\n",
    "# Later on, we shall be changing the data held in the 'df'\n",
    "# variable above. We make a copy here of the original to\n",
    "# compare results against\n",
    "df_original = deepcopy(df)\n",
    "\n",
    "# here we plot 'mBB' - the mass of the jets if we assume they come from\n",
    "# b-jets. \n",
    "plot_variable(df,'mBB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot shows a histogram of the number of events in each 'bin', where 'bin' refers to a range in $m_{bb}$. Signal events (from Higgs) are shown as red blocks. A line representing the concentration of signal events is also included in red. This plot shows, as expected, the highest distribution of signal events to have a mass of ~125 GeV. For the remainder of this notebook, we shall use this variable plot to highlight the effect our other cuts have."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the cuts we will compare the number of signal and background events in each bin to calculate the _signal sensitivity_. Our goal is to apply cuts that isolate as much of the signal as possible and maximise the _signal sensitivity_. \n",
    "\n",
    "\n",
    "# 2.4 Finding Cuts\n",
    "\n",
    "**In this section we will be using the simulated data to determine what cuts must be applied on the kinematic and topoligical parameters to identify the signal region.**\n",
    "\n",
    "\n",
    "To do this we will use the plot_variable() function to visualise how a particular kinematic or topological event variable is distributed for the various process involved. We wll use this distribution to determine the appropriate cuts. Let's use an example to illustrate this concept.\n",
    "\n",
    "The code below plots the distribution of the reconstructed top mass $M_{top}$. The signal (labelled $VH \\rightarrow bb$ in the legend) is shown in red on the histogram. For clarity a red solid line has also been plotted to help identify the sigal region. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The plot_variable takes two arguments. First is the data frame used to plot the distributions and\n",
    "# second is the variable in question. \n",
    "\n",
    "plot_variable(df,'MET')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Exercise 2.4.1 Use the plot variable function to plot another variable (like Mtop) which is the reconstructed mass of the top quark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# make your plot here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.4.1 Plot the event variables and determine the cuts that will isolate the signal region. Note these cuts down in your notebook.\n",
    "\n",
    "\n",
    "An example is shown in the cells below where it was identified that by requiring that Mtop > 225 GeV we eliminate a large amount of the $t\\bar{t}$ and single top background. \n",
    "\n",
    "By changing the variable plotted determine your own list of cuts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload data\n",
    "df = pd.read_csv('VHbb_data_2jet.csv')\n",
    "\n",
    "# Apply cut\n",
    "df = df.loc[df[\"MET\"]/1000 > 50] # Select only events with MET > 50 GeV\n",
    "\n",
    "# The code below plots the mBB distribution after the cut is applied\n",
    "plot_variable(df_original,'mBB')\n",
    "print(\"Sensitivity achieved before cuts \",sensitivity_cut_based(df_original))\n",
    "\n",
    "plot_variable(df,'mBB')\n",
    "\n",
    "print(\"Sensitivity achieved after cuts \",sensitivity_cut_based(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown in the above plots of the $m_{bb}$ distribution, once the cut is applied we eliminate a large amount of $t\\bar{t}$ background.\n",
    "\n",
    "### Determine a set of additional cuts that will help isolate the signal. Each time you optimise a new cut value, note down the new sensitivity. After you have optimised all the cuts, plot the sensitivity increase as each new cut is applied. Code to create plots in python is provided below. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload data\n",
    "df = pd.read_csv('VHbb_data_2jet.csv')\n",
    "\n",
    "# Apply a cut here!\n",
    "# =================\n",
    "\n",
    "\n",
    "\n",
    "# The code below plots the mBB distribution after the cut is applied\n",
    "plot_variable(df_original,'mBB')\n",
    "print(\"Sensitivity achieved before cuts \",sensitivity_cut_based(df_original))\n",
    "\n",
    "plot_variable(df,'mBB')\n",
    "\n",
    "print(\"Sensitivity achieved after cuts \",sensitivity_cut_based(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plotting sensitivity graph\n",
    "\n",
    "# Add the sensitivities you noted down to the list\n",
    "sensitivities = [1.0, 1.1, 1.2, 1.3]\n",
    "\n",
    "# Add variable names to the list below. Make sure you keep the same order\n",
    "variable_names = ['dRBB', 'MET', 'Mtop', 'pTV']\n",
    "\n",
    "num_variables_used = len(sensitivities)\n",
    "\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.set_size_inches(8.5,7)\n",
    "x = list(np.arange(0,num_variables_used,1))\n",
    "plt.bar(x,sensitivities)\n",
    "\n",
    "plt.xticks(x, variable_names);\n",
    "\n",
    "plt.xlabel('Variables')\n",
    "plt.ylabel('Sensitivity')\n",
    "\n",
    "\n",
    "# Once you have finalised your plots you can export a .png file by uncommenting the code below\n",
    "#plt.savefig('cut_based_variable_comparison.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.4.3 Cutting multiple variables\n",
    "\n",
    "So far, we have only asked you to cut on 1 variable at a time. Now, we shall cut on two variables\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload data\n",
    "df = pd.read_csv('VHbb_data_2jet.csv')\n",
    "\n",
    "# The code below plots the mBB distribution after the cut is applied\n",
    "plot_variable(df_original,'mBB')\n",
    "print(\"Sensitivity achieved before cuts \",sensitivity_cut_based(df_original))\n",
    "\n",
    "\n",
    "# Apply first cut\n",
    "df = df.loc[df[\"Mtop\"] / 1e3 > 250] # divide by 1e3 to convert from MeV to GeV\n",
    "print(\"Sensitivity achieved after first cut \",sensitivity_cut_based(df))\n",
    "\n",
    "\n",
    "# Apply second cut\n",
    "df = df.loc[df[\"dRBB\"] > 0.5] \n",
    "print(\"Sensitivity achieved after second cut \",sensitivity_cut_based(df))\n",
    "\n",
    "plot_variable(df,'mBB')\n",
    "\n",
    "print(\"Sensitivity achieved after cuts \",sensitivity_cut_based(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why does applying 2 cuts sometimes decrease sensitivity\n",
    "\n",
    "You may have noticed that some cuts work when we apply them to a single variable, but once we cut two variables at once we sometimes decrease the sensitivity. \n",
    "To see why this happens, we below show how the plot for the variable 'dRBB' changes as we apply cuts on other variables first,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Reload data\n",
    "df = pd.read_csv('VHbb_data_2jet.csv')\n",
    "\n",
    "\n",
    "# The code below plots the mBB distribution after the cut is applied\n",
    "print(\"Sensitivity achieved before cuts \",sensitivity_cut_based(df_original))\n",
    "plot_variable(df,'dRBB')\n",
    "\n",
    "# Apply first cut\n",
    "df = df.loc[df[\"Mtop\"] / 1e3 > 250] # divide by 1e3 to convert from MeV to GeV\n",
    "print(\"Sensitivity achieved after first cut \",sensitivity_cut_based(df))\n",
    "plot_variable(df,'dRBB')\n",
    "\n",
    "# Apply second cut\n",
    "df = df.loc[df[\"dRBB\"] > 0.5] \n",
    "print(\"Sensitivity achieved after second cut \",sensitivity_cut_based(df))\n",
    "plot_variable(df,'dRBB')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we first plot the variable dRBB when no cut has been applied. We then plot the same variable after cutting on Mtop. We see that this drastically changes the distribution of dRBB, as shown in the second plot. Now, the point at which we cut to optimally increase the sensitivity may have moved, as the distribution has now changed.\n",
    "\n",
    "Ideally, we need a method which allows us to place multiple cuts on different variables at once, taking into account how these distributions change as those cuts are applied. To do this in a hand written algorithm would be challenging. Instead, tomorrow we shall introduce a neural network approach that aims to select signal events from our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "In this tutorial you developed a cut-based analysis on Monte Carlo generated ATLAS data to search for the Higgs Boson's decay to a pair of _b_-quarks. This is a tried and tested approach that is much loved by physicists as one can theoretically motivate the cuts to create a signal region. But can we improve on this? In the next tutorial we will be using Machine Learning to push the boundaries of our analysis and try to obtain sensitivity gains. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
